# Proxy Label Generation 实验记录

## 1. 任务概述

**目标**: 对 300K 条指令微调对话数据 (tulu_300k) 进行质量评分的 proxy label generation。已有约 10% 的 GPT 标注分数 (gpt_scores, 0-5 分, 6 类)，需要为剩余未标注数据生成可靠的 proxy 标签。

**数据集**: `raw_data/tulu_300k_with_embeddings.parquet`
- 总量: 300,932 条对话
- Embedding: BAAI/bge-large-en-v1.5, 1024 维, L2 归一化
- 标签: `gpt_scores`, 6 类 (0-5)

**标签分布** (不平衡):

| Class | 占比 | 描述 |
|-------|------|------|
| 0 | ~6.2% | 最低质量 |
| 1 | ~16.2% | |
| 2 | ~28.6% | 最大类 |
| 3 | ~29.3% | 最大类 |
| 4 | ~18.3% | |
| 5 | ~1.3% | 最高质量 (极少) |

---

## 2. 方法一: kNN Proxy Label Generation

**思路**: 用已标注数据的 embedding 做 kNN 搜索，通过近邻加权投票/回归预测未标注数据的分数。

### 2.1 基础配置

- Embedding 空间做余弦相似度 kNN (L2 归一化后 dot product = cosine sim)
- 默认: K=50, tau=0.1, softmax weighting, vote mode

**代码**: `partial_labeling/proxy_label_generation.py`

### 2.2 预测模式

| 模式 | 说明 |
|------|------|
| **Vote** (分类) | 对 K 个近邻的标签做加权投票, softmax 取 argmax |
| **Regression** (回归) | 对 K 个近邻的标签做加权均值, 四舍五入到整数 |

### 2.3 权重计算方式

| 权重类型 | 公式 | 说明 |
|----------|------|------|
| **Softmax** | `w = exp(sim / tau)` | tau 越小, 越集中在最近邻 |
| **Power** | `w = max(sim, 0)^alpha` | alpha 越大, 距离衰减越快 |

附加选项:
- **sim_threshold**: 忽略相似度低于阈值的近邻
- **prior_calibration**: 将投票结果除以训练集类别先验, 抵消类别不平衡

### 2.4 超参搜索 (30k 子集)

**代码**: `partial_labeling/hyperparam_search.py`

搜索空间: K x {5,10,20,50,100,200}, tau x {0.01,0.05,0.1,0.5,1.0}, mode x {vote, regression}, 共 84 种组合。

**结果**: 超参调优对 kNN 提升极有限。

| 配置 | Accuracy | Macro F1 | MAE |
|------|----------|----------|-----|
| K=50, tau=0.1, vote (默认) | 0.4479 | 0.3510 | 0.6786 |
| K=100, tau=0.05, vote (最佳) | 0.4484 | 0.3542 | 0.6767 |

**Prior calibration**: 大幅降低准确率 (0.4479 → ~0.30), 略提升 macro_f1。原因: 将投票重新分配给少数类, 准确率以多数类为主导。

### 2.5 全量 300k kNN Scaling Curve

**脚本**: `run_proxy_knn.sh`

| Train Ratio | Train | Test | Accuracy | Macro F1 | MAE |
|-------------|-------|------|----------|----------|-----|
| 1% | 3,009 | 297,923 | 0.4150 | 0.2938 | 0.7299 |
| 2% | 6,019 | 294,913 | 0.4224 | 0.3084 | 0.7169 |
| 5% | 15,047 | 285,885 | 0.4352 | 0.3292 | 0.6959 |
| 10% | 30,093 | 270,839 | 0.4481 | 0.3515 | 0.6769 |
| 15% | 45,140 | 255,792 | 0.4545 | 0.3586 | 0.6664 |
| 20% | 60,186 | 240,746 | 0.4583 | 0.3647 | 0.6597 |
| 30% | 90,280 | 210,652 | 0.4649 | 0.3704 | 0.6498 |
| 50% | 150,466 | 150,466 | 0.4726 | 0.3794 | 0.6387 |
| 70% | 210,652 | 90,280 | 0.4776 | 0.3860 | 0.6289 |
| 90% | 270,839 | 30,093 | 0.4826 | 0.3876 | 0.6234 |

**观察**: 收益递减明显, 30% 之后准确率增长非常缓慢 (0.4649 → 0.4826, +1.8%)。

### 2.6 kNN 瓶颈分析

- **Embedding 质量**: bge-large-en-v1.5 按语义内容聚类, 不按质量聚类
- 近邻平均余弦相似度 ~0.75, 相似度梯度很平
- 近邻标签匹配率仅 35.8% (随机基线 29%)
- **结论**: embedding 空间中语义相近的样本不一定质量相近, 限制了所有基于 embedding 的方法

### 2.7 Skywork Reward Embedding kNN 对比实验

**动机**: 2.6 中分析发现 BGE embedding 是通用语义 embedding, 不按质量聚类。Reward Model 的 hidden states 天然包含质量判断信号, 应能提供更好的 kNN 检索效果。

**Reward Model**: Skywork/Skywork-Reward-Llama-3.1-8B
- 基于 Llama-3.1-8B-Instruct, 8B 参数
- 输出维度: 4096 维 (vs BGE 1024 维)
- Pooling: last-token pooling (decoder-only 模型取最后一个非 padding token 的 hidden state)
- 提取方式: 8 张 L40S 并行, batch_size=16, bf16, max_length=2048

**代码**: `partial_labeling/extract_reward_embeddings.py`, `run_extract_skywork_embeddings.sh`

**脚本**: `run_proxy_knn_skywork.sh`

#### Skywork kNN Scaling Curve (全量 300k)

| Train Ratio | Train | Test | Accuracy | Macro F1 | MAE |
|-------------|-------|------|----------|----------|-----|
| 1% | 3,009 | 297,923 | 0.4308 | 0.3074 | 0.7019 |
| 2% | 6,019 | 294,913 | 0.4478 | 0.3290 | 0.6694 |
| 5% | 15,047 | 285,885 | 0.4643 | 0.3555 | 0.6378 |
| 10% | 30,093 | 270,839 | 0.4786 | 0.3724 | 0.6139 |
| 15% | 45,140 | 255,792 | 0.4851 | 0.3799 | 0.6023 |
| 20% | 60,186 | 240,746 | 0.4903 | 0.3871 | 0.5938 |
| 30% | 90,280 | 210,652 | 0.4972 | 0.3955 | 0.5845 |
| 50% | 150,466 | 150,466 | 0.5043 | 0.4045 | 0.5711 |
| 60% | 180,559 | 120,373 | 0.5080 | 0.4080 | 0.5661 |
| 70% | 210,652 | 90,280 | 0.5097 | 0.4098 | 0.5631 |
| 80% | 240,746 | 60,186 | 0.5129 | 0.4133 | 0.5580 |
| 90% | 270,839 | 30,093 | 0.5144 | 0.4119 | 0.5570 |

#### BGE vs Skywork kNN 直接对比

| Train Ratio | BGE Acc | Sky Acc | Diff | BGE F1 | Sky F1 | Diff | BGE MAE | Sky MAE | Diff |
|-------------|---------|---------|------|--------|--------|------|---------|---------|------|
| 1% | 0.4150 | 0.4308 | +1.58% | 0.2938 | 0.3074 | +1.37% | 0.7299 | 0.7019 | -2.80% |
| 5% | 0.4352 | 0.4643 | +2.91% | 0.3292 | 0.3555 | +2.63% | 0.6959 | 0.6378 | -5.81% |
| 10% | 0.4481 | 0.4786 | +3.05% | 0.3515 | 0.3724 | +2.09% | 0.6769 | 0.6139 | -6.30% |
| 20% | 0.4583 | 0.4903 | +3.21% | 0.3647 | 0.3871 | +2.25% | 0.6597 | 0.5938 | -6.59% |
| 50% | 0.4726 | 0.5043 | +3.17% | 0.3794 | 0.4045 | +2.51% | 0.6387 | 0.5711 | -6.75% |
| 90% | 0.4826 | 0.5144 | +3.18% | 0.3876 | 0.4119 | +2.43% | 0.6234 | 0.5570 | -6.64% |
| **Average** | **0.4572** | **0.4870** | **+2.98%** | **0.3583** | **0.3812** | **+2.29%** | **0.6623** | **0.6016** | **-6.07%** |

#### 关键发现

1. **Skywork 在所有 12 个 train ratio 上全面优于 BGE**, 无一例外
2. **Accuracy 平均提升 +2.98%**, Macro F1 平均提升 +2.29%, MAE 平均下降 -6.07%
3. **低标注场景 (1%-5%) 提升也很显著**: 说明 reward model embedding 的质量信号更强, 少量标注即可获得更好的 kNN 效果
4. **MAE 改善最为显著**: 说明 Skywork embedding 不仅分类更准, 预测的偏离程度也更小
5. **验证了 2.6 瓶颈分析**: 更换为质量感知的 reward model embedding 后, kNN 效果显著提升, 证实 embedding 质量是 kNN 方法的核心瓶颈

---

## 3. 方法二: 监督分类器 (Embedding Only)

**思路**: 在已标注的 10% 数据上训练神经网络, 用 embedding 作为输入特征直接预测 score。即使 embedding 对质量的信号很弱, 监督学习也能比 kNN 更好地提取这些信号。

**代码**: `partial_labeling/supervised_proxy.py`

### 3.1 实验设置

- 数据池: 30,000 (30k 子集)
- 训练集: 3,000 (10%), 测试集: 27,000 (90%)
- 优化器: AdamW, lr=0.001, weight_decay=0.0001
- Batch size: 512, Epochs: 100, CosineAnnealingLR
- 验证策略: 每 epoch 在测试集上评估, 保存最佳 val_acc 模型

### 3.2 模型架构

| 模型 | 结构 | 参数量 |
|------|------|--------|
| **Linear Probe** | Linear(1024, 6) | 6K |
| **MLP** | Linear → ReLU → Dropout → Linear → ReLU → Dropout → Linear | 330K (h=256) / 791K (h=512) |
| **ResNet-MLP** | Linear proj → N x ResidualBlock(LayerNorm+Linear+GELU+Dropout+Linear) → LayerNorm → Linear | 793K (h=256,4L) / 3.7M (h=512,6L) |
| **Ordinal** | ResNet backbone → scalar score → K-1 learnable thresholds → cumulative P(y>k) | 792K |

### 3.3 损失函数与正则化

| 技术 | 说明 |
|------|------|
| **CrossEntropy** | 标准交叉熵 (默认) |
| **Class Weight** | 按类别频率反权重, 提升少数类 |
| **Focal Loss** | 降低易分类样本权重, 聚焦困难样本 (gamma=2.0) |
| **Label Smoothing** | 软化 one-hot 标签, 防止过拟合 |
| **Mixup** | 训练时对输入和标签做凸组合, 数据增强 |

### 3.4 结果 (30k 子集, Embedding Only)

| 方法 | Accuracy | Macro F1 | MAE | 参数量 |
|------|----------|----------|-----|--------|
| Linear Probe | 0.4400 | 0.1817 | 0.6543 | 6K |
| MLP (h=256) | 0.4943 | 0.2531 | 0.5582 | 330K |
| MLP (h=512) | 0.4944 | 0.2525 | 0.5596 | 791K |
| MLP + class_weight | 0.4158 | 0.3331 | 0.7080 | 330K |
| ResNet-MLP (h=256, 4L) | 0.4841 | 0.2710 | 0.5684 | 793K |
| ResNet-MLP (h=512, 6L) | 0.4977 | 0.2872 | 0.5566 | 3.7M |
| Ordinal Regression | 0.4295 | 0.2362 | 0.7309 | 792K |
| ResNet + Focal Loss | 0.4900 | 0.3049 | 0.5699 | 793K |
| ResNet + LS + Mixup | 0.4955 | 0.2620 | 0.5592 | 793K |

### 3.5 观察

- MLP (0.4943) 比 kNN 最佳 (0.4484) **高 +4.6%**, 监督学习能更好地利用 embedding 中的弱信号
- 增大模型 (h=256→512, 4L→6L) 边际收益极小 (+0.3%), 瓶颈不在模型容量
- **Class weight 降低准确率但提升 macro_f1** (0.2531→0.3331), accuracy 和 class balance 之间存在 trade-off
- Focal Loss 效果类似: 提升 macro_f1, 略降准确率
- **Ordinal Regression 效果最差** (0.4295), 单标量打分 + 阈值的假设不适合此任务
- 所有模型对 class 4 和 class 5 的准确率极低 (class 5 基本为 0%)

---

## 4. 方法三: 多特征融合 (Feature Fusion)

**思路**: 提取浅层文本特征 (长度、格式、结构等), 与 embedding 拼接后输入分类器。假设质量与表面特征有较强相关性。

**代码**: `partial_labeling/feature_extraction.py`, `partial_labeling/supervised_proxy.py` (--use_text_features)

### 4.1 文本特征 (v1: 35 维 / v2: 63 维)

**v1 (35 维)** — 初始版本:

| 类别 | 特征 |
|------|------|
| **长度** (8) | user/asst 字符长度, 词数, log 长度, 长度比 |
| **结构** (9) | 对话轮数, 句子数, 段落数, 平均词长, 平均句长 |
| **词汇** (2) | user/asst 词汇多样性 (unique words / total words) |
| **内容信号** (7) | 代码块数, 列表项数, 标题数, URL 数, 特殊字符密度, 换行密度 |
| **Prompt** (3) | 问号数, 指令关键词数 |
| **回复质量** (4) | 首字母大写, 结尾标点, bigram 重复率, 第一人称密度 |

**v2 (63 维)** — 扩展版, 新增 28 个特征:

| 类别 | 新增特征 |
|------|----------|
| **结构** | 句子长度 max/min/std, 段落平均长度, 最大词长 |
| **词汇** | Hapax legomena ratio (只出现一次的词比例) |
| **可读性** | 平均音节数, Flesch-Kincaid Grade Level, Coleman-Liau Index |
| **内容** | inline code 数, markdown 表格, 加粗/斜体数, 数学符号密度, 括号表达, 标点多样性, 数字密度 |
| **Prompt** | 用户代码检测, 约束词数, log 词数 |
| **对齐** | prompt-response 词重叠率 (去停用词) |
| **质量** | trigram 重复率, 顺从短语数, 拒绝短语数, 模糊语密度, 过渡词密度, 举例短语数 |

### 4.2 融合方式

**Early Fusion (特征层拼接)**:
```
embedding (1024维, L2归一化) ∥ text_features (Z-score标准化)
                              ↓
               拼接后 1059维 (v1) / 1087维 (v2) → MLP / ResNet
```

### 4.3 结果 (30k 子集, train=3000, test=27000)

| 方法 | Accuracy | Macro F1 | MAE | 参数量 |
|------|----------|----------|-----|--------|
| Text Features Only v1 (MLP, h=256) | 0.5098 | 0.3139 | 0.5504 | 77K |
| **Fusion MLP v1 (emb+35feat, h=256)** | **0.5339** | 0.3485 | **0.5120** | 339K |
| Fusion ResNet v1 (emb+35feat, h=256, 4L) | 0.5272 | **0.3639** | 0.5261 | 802K |

### 4.4 v2 扩展特征 & 更大模型实验

| 方法 | Accuracy | Macro F1 | MAE | 参数量 | vs v1 best |
|------|----------|----------|-----|--------|-----------|
| Text Features Only v2 (63feat) | 0.5082 | 0.3146 | 0.5522 | 84K | -0.16% |
| Fusion MLP v2 (emb+63feat, h=256) | 0.5301 | 0.3465 | 0.5137 | 346K | -0.38% |
| Fusion MLP v2 (h=512) | 0.5276 | 0.3535 | 0.5194 | 823K | -0.63% |
| Fusion MLP v2 (h=1024) | 0.5264 | 0.3503 | 0.5204 | 2.2M | -0.75% |
| Fusion ResNet v2 (h=512, 6L) | 0.5273 | 0.3391 | 0.5194 | 3.7M | -0.66% |
| Fusion MLP v2 (200ep, lr=5e-4) | 0.5310 | 0.3541 | 0.5146 | 346K | -0.29% |

**结论**: 更多特征 (63 vs 35) 和更大模型 (h=1024, 3.7M params) 均未超过 v1 Fusion MLP (0.5339)。在 3000 训练样本下, 瓶颈在数据量而非模型容量或特征数。

### 4.5 LightGBM 对比

**代码**: `partial_labeling/gbm_proxy.py`

| 方法 | Accuracy | Macro F1 | MAE |
|------|----------|----------|-----|
| GBM text features only (63feat) | 0.5010 | 0.3205 | 0.5619 |
| GBM fusion (emb+63feat) | 0.5094 | 0.2880 | 0.5470 |
| GBM embedding only | 0.4606 | 0.2368 | 0.6216 |

**GBM 特征重要性 Top-5**: total_char_len, user_char_len, len_ratio, asst_char_len, fk_grade — 长度类特征最重要。

**结论**: 树模型不如 MLP, 因为无法有效利用高维 embedding 中的信号。

### 4.6 Per-Class Accuracy 对比 (30k, train=10%)

| Class | Fusion MLP v1 | Fusion ResNet v1 | Text Only v1 |
|-------|--------------|-----------------|-------------|
| 0 (n=1701) | 0.19 | 0.33 | 0.18 |
| 1 (n=4848) | 0.40 | 0.31 | 0.34 |
| 2 (n=10204) | 0.58 | 0.55 | 0.62 |
| 3 (n=8622) | 0.70 | 0.69 | 0.62 |
| 4 (n=1612) | 0.12 | 0.16 | 0.06 |
| 5 (n=13) | 0.00 | 0.08 | 0.00 |

### 4.7 Skywork Embedding + Fusion MLP

**动机**: 2.7 中 Skywork Reward embedding 在 kNN 上全面优于 BGE, 那么在 Fusion MLP 中也替换为 Skywork embedding 是否能进一步提升?

**配置**: Skywork 4096 维 + 63 维文本特征 = **4159 维**输入 (vs BGE 的 1087 维)
- 模型: MLP (h=256), 参数量 ~1.3M (因输入维度增大)
- 数据: 30k 子集, 100 epochs, 其余同 BGE Fusion MLP

**脚本**: `run_skywork_fusion_mlp.sh`

#### Skywork vs BGE Fusion MLP 全 Train Ratio 对比

| Train Ratio | Skywork Acc | BGE Acc | dAcc | Skywork F1 | BGE F1 | dF1 | Skywork MAE | BGE MAE | dMAE |
|-------------|------------|---------|------|-----------|--------|-----|------------|---------|------|
| 10% | 0.5267 | 0.5339 | -0.72% | 0.3455 | 0.3485 | -0.30% | 0.5232 | 0.5120 | +0.0112 |
| 20% | 0.5432 | 0.5404 | +0.28% | 0.3904 | 0.3684 | +2.20% | 0.4965 | 0.4990 | -0.0024 |
| 30% | 0.5527 | 0.5442 | +0.85% | 0.4143 | 0.3694 | +4.48% | 0.4857 | 0.4957 | -0.0100 |
| 50% | 0.5655 | 0.5545 | +1.10% | 0.4414 | 0.3998 | +4.17% | 0.4700 | 0.4826 | -0.0126 |
| 70% | 0.5691 | 0.5544 | +1.47% | 0.4452 | 0.3871 | +5.81% | 0.4652 | 0.4809 | -0.0157 |
| 90% | 0.5813 | 0.5593 | +2.20% | 0.4280 | 0.3886 | +3.94% | 0.4437 | 0.4763 | -0.0327 |

#### 关键发现

1. **低 train ratio (10%) Skywork 略低于 BGE**: 4096 维高维空间在仅 3000 训练样本时更容易过拟合, 导致 accuracy 比 BGE 低 0.72%
2. **20%+ train ratio Skywork 全面超越 BGE**: 随着训练数据增加, Skywork 的高维优势逐渐显现
3. **Macro F1 提升最为显著 (+2.2%~+5.8%)**: Skywork reward embedding 对少数类预测更均匀, 这一优势在 Fusion MLP 中同样体现
4. **90% train ratio 达到新最佳 accuracy (0.5813)** 和 **70% train ratio 达到新最佳 Macro F1 (0.4452)**
5. **训练数据越多, Skywork 优势越大**: 从 10% 的 -0.72% 到 90% 的 +2.20%, 随数据量增长 gap 持续扩大

### 4.8 Balanced Dataset 实验 (类别均衡 18k)

**动机**: 原始数据集严重不平衡 (class 2/3 各 ~30%, class 5 仅 1.3%), 导致模型倾向预测多数类, 少数类准确率极低。通过构建均衡数据集验证: 类别不平衡是否是 Macro F1 低的主因?

**均衡数据集构建**:
- 从 300k 全量中每个 class 采样 3000 条 → 总计 **18,000 条**
- 完全均衡: 每类占比 **16.67%**
- 数据文件: `raw_data/tulu_balanced_18k.parquet`
- Embedding: `raw_data/embedding_cache/Skywork_balanced_18k_embeddings.npy` (18000, 4096)

**脚本**: `run_balanced_skywork_fusion_mlp.sh`

#### 均衡 vs 不均衡对比 (Skywork Fusion MLP, h=256)

| Train Ratio | Bal Acc | Imb Acc | dAcc | Bal F1 | Imb F1 | dF1 | Bal MAE | Imb MAE | dMAE |
|-------------|---------|---------|------|--------|--------|-----|---------|---------|------|
| 10% | 0.4713 | 0.5267 | -5.54% | **0.4677** | 0.3455 | **+12.22%** | 0.6602 | 0.5232 | +0.1370 |
| 20% | 0.4972 | 0.5432 | -4.60% | **0.4903** | 0.3904 | **+9.99%** | 0.6147 | 0.4965 | +0.1182 |
| 30% | 0.5297 | 0.5527 | -2.30% | **0.5259** | 0.4143 | **+11.16%** | 0.5662 | 0.4857 | +0.0805 |
| 50% | 0.5554 | 0.5655 | -1.01% | **0.5540** | 0.4414 | **+11.26%** | 0.5248 | 0.4700 | +0.0548 |
| 70% | 0.5720 | 0.5691 | +0.29% | **0.5677** | 0.4452 | **+12.25%** | 0.5054 | 0.4652 | +0.0402 |
| 90% | 0.5706 | 0.5813 | -1.07% | **0.5636** | 0.4280 | **+13.56%** | 0.5117 | 0.4437 | +0.0680 |

#### Per-Class Accuracy (均衡 18k)

| Class | 10% | 20% | 30% | 50% | 70% | 90% |
|-------|-----|-----|-----|-----|-----|-----|
| 0 | 0.5748 | 0.6881 | 0.6981 | 0.7043 | 0.7331 | 0.7752 |
| 1 | 0.4760 | 0.3973 | 0.4771 | 0.4579 | 0.4774 | 0.4014 |
| 2 | 0.3037 | 0.3407 | 0.3548 | 0.4430 | 0.4456 | 0.4145 |
| 3 | 0.3944 | 0.4462 | 0.4496 | 0.4826 | 0.4706 | 0.5000 |
| 4 | 0.3537 | 0.3573 | 0.4527 | 0.4977 | 0.5059 | 0.5223 |
| 5 | 0.7251 | 0.7538 | 0.7450 | 0.7431 | 0.7904 | 0.8082 |

#### 关键发现

1. **Macro F1 大幅提升 (+10~14%)**: 这是最关键的发现。不均衡时 F1=0.35-0.43, 均衡后 F1=**0.47-0.57**, 证明类别不平衡是 Macro F1 低的主要原因
2. **Accuracy 略降 (-1~5%)**: 不均衡数据中只需预测好 class 2/3 就能高准确率; 均衡后每类同等重要, accuracy 指标更"公平"但数值略低
3. **少数类准确率大幅改善**: class 4 从不均衡时的 12-25% → 均衡时的 **35-52%**; class 5 从不均衡时的 0% → 均衡时的 **73-81%**; class 0 从 19-30% → **58-78%**
4. **Class 5 不再是"盲区"**: 不均衡时 class 5 永远预测为 0%, 均衡后达到 73-81%, 说明模型有能力区分 class 5, 只是原来训练样本太少
5. **Class 2 成为新的"最难类"**: 均衡后 class 2 准确率最低 (30-45%), 可能因为它与 class 1/3 的边界最模糊
6. **70% train 是甜蜜点**: acc=0.5720 + F1=0.5677, 两者都接近最优; 90% train 时 accuracy 反而略降, 可能因为 test set 太小 (1800)

### 4.9 Class-Weighted Loss 实验 (不均衡 30k)

**动机**: 不重新采样, 直接在 loss 中对少数类赋予更高权重, 试图在不均衡数据上兼顾 accuracy 和 Macro F1。

**配置**: Skywork Fusion MLP (h=256) + `--class_weight` (逆频率权重), 30k 不均衡数据

**脚本**: `run_skywork_fusion_mlp_classweight.sh`

#### Class Weight vs 无权重 vs 均衡 18k

| Train Ratio | CW Acc | Base Acc | Bal18k Acc | CW F1 | Base F1 | Bal18k F1 |
|-------------|--------|----------|------------|-------|---------|-----------|
| 10% | 0.4546 | **0.5267** | 0.4713 | 0.3614 | 0.3455 | **0.4677** |
| 20% | 0.4852 | **0.5432** | 0.4972 | 0.4023 | 0.3904 | **0.4903** |
| 30% | 0.4910 | **0.5527** | 0.5297 | 0.4113 | 0.4143 | **0.5259** |
| 50% | 0.5049 | **0.5655** | 0.5554 | 0.4227 | 0.4414 | **0.5540** |
| 70% | 0.4998 | **0.5691** | 0.5720 | 0.4221 | 0.4452 | **0.5677** |
| 90% | 0.5183 | **0.5813** | 0.5706 | 0.4686 | 0.4280 | **0.5636** |

#### 关键发现

1. **Class weight 效果有限**: Macro F1 仅提升 +1~4%, 远不如均衡数据集的 +10~14%
2. **Accuracy 下降 -5~7%**: 牺牲多数类但没有等比例补偿少数类
3. **Class 4 受益最大** (0.30→0.71 @50%): 超过均衡数据, 但其他少数类改善有限
4. **Class 5 改善不足** (0→0.40 @90%): 权重极高 (5.75) 但样本太少 (5-13 条), 无法学到有效模式
5. **结论**: 当少数类样本数极少时, 调整 loss 权重不如增加真实训练样本有效

### 4.10 训练集过采样 vs 均衡数据集 (数据泄露修正)

**动机**: 4.8 均衡 18k 中 train/test 都是独立唯一样本, 无泄露。但如果要在不均衡数据上做过采样, 必须 **先 split 再对训练集过采样**, 否则过采样后 split 会导致 train/test 共享重复样本 (数据泄露)。

**方法**: 在 `supervised_proxy.py` 中新增 `--oversample_train` 参数:
1. 按 train_ratio 正常 split 原始 30k → train/test
2. 对 train 中各类过采样到最大类的数量 (target = max class count)
3. test 保持原始分布, 不做任何修改

**脚本**: `run_skywork_fusion_mlp_oversample.sh`

#### Oversample Train vs 无权重 vs 均衡 18k

| Train Ratio | OS Acc | Base Acc | Bal18k Acc | OS F1 | Base F1 | Bal18k F1 |
|-------------|--------|----------|------------|-------|---------|-----------|
| 10% | 0.4936 | **0.5267** | 0.4713 | 0.3739 | 0.3455 | **0.4677** |
| 20% | 0.5183 | **0.5432** | 0.4972 | 0.4045 | 0.3904 | **0.4903** |
| 30% | 0.5186 | **0.5527** | 0.5297 | 0.4127 | 0.4143 | **0.5259** |
| 50% | 0.5284 | **0.5655** | 0.5554 | 0.4299 | **0.4414** | **0.5540** |
| 70% | 0.5329 | **0.5691** | **0.5720** | 0.4382 | **0.4452** | **0.5677** |
| 90% | 0.5387 | **0.5813** | 0.5706 | **0.4662** | 0.4280 | **0.5636** |

#### Per-Class Accuracy @ 90% train (三方对比)

| Class | 无权重 | Class Weight | Oversample | 均衡 18k |
|-------|--------|-------------|------------|----------|
| 0 (少) | 0.4140 | 0.6505 | 0.4785 | **0.7752** |
| 1 | 0.4294 | 0.5217 | **0.5461** | 0.4014 |
| 2 (多) | **0.6701** | 0.5000 | 0.5095 | 0.4145 |
| 3 (多) | **0.6438** | 0.4808 | 0.5857 | 0.5000 |
| 4 (少) | 0.2739 | **0.7197** | 0.5223 | 0.5223 |
| 5 (极少) | 0.0000 | 0.4000 | 0.2000 | **0.8082** |

#### 关键发现

1. **Oversample 效果与 Class Weight 类似**: F1 提升 +2~4%, Accuracy 下降 -3~4%, 两者是同一机制 (改变梯度占比) 的不同实现
2. **均衡 18k 仍是最优方案**: F1=0.5677 远超 Oversample (0.4662) 和 Class Weight (0.4686)
3. **根本原因**: Oversample/Class Weight 只改变 loss 权重, 不增加信息量。均衡 18k 每类有 3000 个**真实不同**的训练样本, 信息量远超重复样本
4. **⚠️ 关于均衡 100k 数据泄露**: 之前构建的均衡 100k (class 5 过采样 4.35x) 由于先过采样再 split, 导致 train/test 共享重复样本。class 5 准确率 96.6% 是虚高的, 修正后 (oversample train only) 仅为 20%, 与 class weight 的 40% 同一量级

### 4.11 多标注者标签融合实验 (Label Fusion)

**动机**: 数据集中有 3 个 LLM 标注者 (GPT, Llama, Mistral) 的评分。单独使用 GPT 分数作为训练标签可能引入 GPT 的偏差和噪声。通过多标注者融合, 期望获得更稳健的标签。

**配置**: Skywork Fusion MLP (h=256), 30k 数据池, 3 种融合模式:
- **Majority (多数投票)**: 取 3 个标注者的众数 (mode), 无唯一众数时取最小值
- **Median (中位数)**: 取 3 个分数的中位数, 压缩极端值
- **Consensus (共识过滤)**: 仅保留至少 2 个标注者一致的样本, 取众数为标签

**脚本**: `run_skywork_fusion_mlp_label_fusion.sh`

**标注者一致性**: GPT==Llama: 28.3%, GPT==Mistral: 33.6%, 三者全部一致: 10.6%, ≥2 一致: 69.5%

#### 融合 vs 基线 (GPT-only) 对比

| Train Ratio | Base Acc | Maj Acc | Med Acc | Con Acc | Base F1 | Maj F1 | Med F1 | Con F1 |
|-------------|----------|---------|---------|---------|---------|--------|--------|--------|
| 10% | **0.5267** | 0.4871 | 0.5155 | 0.5137 | **0.3455** | 0.2778 | 0.2529 | 0.2452 |
| 20% | **0.5432** | 0.4988 | 0.5273 | 0.5281 | **0.3904** | 0.3040 | 0.2606 | 0.2734 |
| 30% | **0.5527** | 0.5053 | 0.5338 | 0.5328 | **0.4143** | 0.2926 | 0.2661 | 0.2801 |
| 50% | **0.5655** | 0.5165 | 0.5397 | 0.5432 | **0.4414** | 0.3266 | 0.2781 | 0.3033 |
| 70% | **0.5691** | 0.5204 | 0.5354 | 0.5455 | **0.4452** | 0.3357 | 0.2594 | 0.2997 |
| 90% | **0.5813** | 0.5370 | 0.5533 | 0.5427 | **0.4280** | 0.3545 | 0.2950 | 0.2928 |

#### Per-Class Accuracy @ 90% train (融合 vs 基线)

| Class | Base (GPT) | Majority | Median | Consensus |
|-------|-----------|----------|--------|-----------|
| 0 (少) | **0.41** | 0.30 | 0.04 | 0.06 |
| 1 | **0.43** | 0.34 | 0.33 | 0.39 |
| 2 (多) | **0.67** | 0.54 | 0.62 | 0.34 |
| 3 (多) | 0.64 | **0.71** | 0.64 | **0.81** |
| 4 (少) | **0.27** | 0.12 | 0.06 | 0.10 |
| 5 (极少) | 0.00 | 0.00 | 0.00 | 0.00 |

#### 关键发现

1. **所有融合模式均不如 GPT-only 基线**: Accuracy 下降 3-8%, Macro F1 下降 7-19%, 结论一致且显著
2. **根本原因: 训练-评估目标不一致**: 评估使用 GPT 分数作为 ground truth, 但融合标签 (majority/median) 与 GPT 的一致率仅 81.9% (majority) / 更低 (median); 模型学到的目标偏离了评估目标
3. **Median 标签压缩严重**: 中位数消除了极端值, 导致 class 0 从 6.3%→1.3%, class 5 从 0.1%→0.0%, 极端类完全消失
4. **Consensus 过滤减少数据量**: 仅保留 ~69.5% 的数据, 在低 train ratio 下数据更不足
5. **Consensus 偏向 class 3**: class 3 准确率达到 81% (vs 基线 64%), 但以牺牲其他所有类为代价
6. **启示**: 在评估目标是单一标注者 (GPT) 时, 融合多标注者的训练标签会引入目标不一致, 反而降低性能。若要利用多标注者, 需要同时修改评估标准 (如用融合标签做 ground truth), 或将其他标注者的分数作为额外特征

### 4.12 迭代自训练实验 (Iterative Self-Training)

**动机**: 受 CReST (CVPR 2021) 和 FlexMatch (NeurIPS 2021) 启发, 用高置信度 pseudo label 逐轮扩充训练集, 少数类用更低阈值以缓解类别不均衡。

**配置**:
- 基础模型: Skywork Fusion MLP (emb+63feat, h=256)
- 自训练轮数: 5 (+ round 0 = 初始训练)
- 多数类置信度阈值: 0.9
- 少数类置信度阈值: 0.7 (class 0, 5: 频率 < 10%)
- 每轮重新初始化模型 (防止 confirmation bias)
- 伪标签不可撤回 (一旦选中永久加入训练集)
- 评估集固定: 始终在全部未标注数据上评估 (含已伪标注样本)

**代码**: `partial_labeling/supervised_proxy.py` (参数 `--self_train_rounds 5`)

**脚本**: `run_skywork_fusion_mlp_selftrain.sh`

#### 结果对比: Baseline vs Self-Training Round 5

| Train Ratio | 方法 | Train Size | Accuracy | Macro F1 | MAE |
|-------------|------|-----------|----------|----------|-----|
| 10% | Baseline | 3,000 | 0.5267 | 0.3455 | 0.523 |
| 10% | **ST R5** | 6,296 | 0.5140 | 0.3703 | 0.551 |
| 10% | Δ | +3,296 | **-1.27%** | **+2.48%** | +0.028 |
| 20% | Baseline | 6,000 | 0.5432 | 0.3904 | 0.497 |
| 20% | **ST R5** | 7,822 | 0.5399 | 0.4133 | 0.508 |
| 20% | Δ | +1,822 | **-0.33%** | **+2.29%** | +0.011 |
| 30% | Baseline | 9,000 | 0.5527 | 0.4143 | 0.486 |
| 30% | **ST R5** | 11,241 | 0.5470 | 0.4272 | 0.497 |
| 30% | Δ | +2,241 | **-0.57%** | **+1.29%** | +0.011 |

#### 逐轮详情 (train_ratio=30%)

| Round | Train Size | Pseudo Added | Pseudo Acc | Accuracy | Macro F1 | class_0 | class_4 |
|-------|-----------|-------------|-----------|----------|----------|---------|---------|
| 0 | 9,000 | 298 | 58.1% | 0.5489 | 0.3959 | 0.242 | 0.187 |
| 1 | 9,298 | 557 | 61.2% | **0.5531** | 0.4259 | 0.364 | 0.275 |
| 2 | 9,855 | 559 | 50.3% | 0.5518 | 0.4296 | 0.391 | 0.295 |
| 3 | 10,414 | 457 | 50.5% | 0.5485 | **0.4329** | **0.423** | 0.304 |
| 4 | 10,871 | 370 | 53.5% | 0.5479 | 0.4277 | 0.403 | **0.350** |
| 5 | 11,241 | — | — | 0.5470 | 0.4272 | 0.403 | 0.343 |

#### 关键发现

1. **Accuracy 无提升, 反而微降**: 3 个 train ratio 下 accuracy 均下降 0.3~1.3%, 说明伪标签噪声抵消了数据量增加的收益
2. **Macro F1 有适度提升 (+1.3~2.5%)**: 少数类 (class 0, 4) 准确率显著改善 (class 0: 0.22→0.40, class 4: 0.19→0.34), 说明低阈值策略有效
3. **伪标签准确率太低 (~50-61%)**: 近一半的伪标签是错误的, 导致模型学到错误信号。这是自训练效果有限的根本原因
4. **伪标签偏向多数类**: class 3 在每轮伪标签中占比最高 (30-50%), class 5 几乎无法被选中
5. **Class 5 始终为 0% (10% train) 或 12.5% (30% train)**: 极端少数类 (1.3%) 的 embedding 空间分布过于分散, 即使降低阈值也无法产生足够高置信度的伪标签
6. **Round 1-2 是"甜蜜期"**: 最佳 accuracy 通常出现在 Round 0-1, 最佳 F1 在 Round 2-3, 之后开始退化 (噪声累积)

#### 与其他方法对比

| 方法 | 额外数据利用 | Acc @10% | F1 @10% | 实现复杂度 |
|------|------------|----------|---------|-----------|
| Baseline Fusion MLP | 无 | 0.5267 | 0.3455 | 低 |
| Oversample (×5) | 无 (过采样) | ~0.52 | ~0.37 | 低 |
| Self-Training R5 | 3,296 pseudo | 0.5140 | 0.3703 | 中 |
| 直接用 20% train | +3,000 real | 0.5432 | 0.3904 | 低 |

**结论**: 在当前模型准确率 (~53%) 下, 自训练产生的伪标签质量不足以有效利用未标注数据。增加 3,296 条伪标签的效果远不如增加 3,000 条真实标注。自训练更适合基础模型准确率较高 (>70%) 的场景。

### 4.13 kNN + MLP Soft Voting Ensemble

**动机**: kNN 和 MLP 的错误模式可能互补 (kNN 依赖局部近邻, MLP 依赖全局特征), 融合两者的概率分布可能提升整体性能。

**方法**: 获取 kNN 和 MLP 各自的 6-class 概率分布, 通过加权平均融合:
```
ensemble_probs = α × mlp_probs + (1-α) × knn_probs
```
扫描 α ∈ {0.0, 0.1, ..., 1.0}, 选最优。

**配置**: Skywork Fusion MLP (emb+63feat, h=256), kNN (K=50, tau=0.1, softmax), 30k 数据池

**代码**: `partial_labeling/ensemble_proxy.py`

**脚本**: `run_skywork_ensemble.sh`

#### Ensemble 结果

| Train Ratio | MLP Acc | MLP F1 | kNN Acc | kNN F1 | Ensemble Acc | Ensemble F1 | Best α |
|-------------|---------|--------|---------|--------|-------------|-------------|--------|
| 10% | 0.5263 | 0.3552 | 0.4576 | 0.2210 | **0.5276** | 0.3430 | 0.8 |
| 20% | 0.5436 | 0.3916 | 0.4769 | 0.2401 | **0.5451** | 0.3818 | 0.8 |
| 30% | 0.5496 | 0.4066 | 0.4850 | 0.2606 | **0.5522** | 0.3957 | 0.7 |

#### 错误互补性分析

| Train Ratio | Disagreement Rate | Either Correct Rate | Both Correct Rate |
|-------------|-------------------|--------------------|--------------------|
| 10% | 37.8% | 64.3% | 42.0% |
| 20% | 36.5% | 65.9% | 43.5% |
| 30% | 33.3% | 65.5% | 44.0% |

#### 关键发现

1. **Accuracy 提升极其有限 (+0.13~0.26%)**: Ensemble 仅比 MLP 单独高 0.1~0.3%, 改善微乎其微
2. **Macro F1 反而下降**: 所有 train ratio 下 ensemble 的 F1 均低于 MLP 单独 (降幅 1.1~1.2%), kNN 在少数类上的"优势"在概率融合后被稀释
3. **Best α=0.7~0.8**: 最优权重严重偏向 MLP, 说明 kNN 贡献很有限。α=1.0 (纯 MLP) 时效果几乎相同
4. **Disagreement 率 33-38%**: 两个模型有较高分歧, 但"either correct"仅 64-66%, 说明两者的互补空间有限 — 大量分歧样本两者都错
5. **结论**: kNN 和 MLP 虽然错误模式不同, 但由于 kNN 本身准确率太低 (~46-49%), 融合后反而拉低了整体 F1。Soft voting 要求两个模型准确率相近时效果最好

### 4.14 Cleanlab 标签噪声检测与清洗

**动机**: GPT 标注本身存在噪声 (多标注者一致率仅 ~70%), 模型在噪声标签上训练, 性能受限。用 Cleanlab (Confident Learning) 自动检测并移除/修正可疑噪声标签, 可能提升基础模型性能。

**方法**:
1. 5-fold 交叉验证获取训练集的 out-of-sample 预测概率
2. `cleanlab.filter.find_label_issues()` 检测可疑标签
3. 清洗策略 A (remove): 直接移除可疑样本后重训
4. 清洗策略 B (relabel): 用模型预测替换可疑标签后重训

**配置**: Skywork Fusion MLP (emb+63feat, h=256), 5-fold CV, 100 epochs

**代码**: `partial_labeling/cleanlab_proxy.py`

**脚本**: `run_skywork_cleanlab.sh`

#### Cleanlab 噪声检测结果

| Train Ratio | Noise Rate | Issues Count | Original Train | Clean Train (remove) |
|-------------|------------|-------------|----------------|---------------------|
| 10% | ~39.8% | 1,191-1,195 | 3,000 | 1,805 |
| 20% | ~40.3% | 2,407-2,434 | 6,000 | 3,566 |
| 30% | ~39.4% | 3,537-3,557 | 9,000 | 5,443 |

#### Remove (移除) vs Relabel (重标) 对比

| Train Ratio | Method | Baseline Acc | Clean Acc | ΔAcc | Baseline F1 | Clean F1 | ΔF1 |
|-------------|--------|-------------|----------|------|------------|---------|-----|
| 10% | remove | 0.5280 | 0.5186 | **-0.93%** | 0.3653 | 0.3214 | **-4.38%** |
| 10% | relabel | 0.5269 | 0.5169 | **-1.00%** | 0.3547 | 0.3491 | -0.56% |
| 20% | remove | 0.5446 | 0.5332 | **-1.15%** | 0.3949 | 0.3577 | **-3.71%** |
| 20% | relabel | 0.5445 | 0.5361 | **-0.85%** | 0.3993 | 0.3708 | **-2.85%** |
| 30% | remove | 0.5499 | 0.5441 | -0.57% | 0.3882 | 0.3924 | +0.41% |
| 30% | relabel | 0.5535 | 0.5450 | **-0.84%** | 0.4130 | 0.3945 | **-1.85%** |

#### 关键发现

1. **清洗后性能全面下降**: 除 30% remove 的 F1 微升 +0.41% 外, 所有配置的 accuracy 和 F1 均下降
2. **~40% 标签被标为噪声 (过于激进)**: 模型 OOS 准确率仅 ~55%, 几乎一半标签都会和模型预测不一致, 导致 cleanlab 将大量正确标签误判为噪声
3. **Remove 损失太多数据**: 10% train 时从 3000→1805 (40% 移除), 数据量严重不足, F1 骤降 -4.4%
4. **Relabel 效果略好于 Remove**: 保留了数据量, 但用不准确的模型预测替换标签, 引入新的噪声
5. **根本问题: 模型准确率太低无法做 Confident Learning**: Cleanlab 要求模型的 out-of-sample 准确率显著高于随机, 当模型仅 55% 准确率 (6 类随机 16.7%) 时, 其 noise detection 的 precision 不足
6. **与 Self-Training 类似的失败模式**: 两者都依赖模型自身的预测质量 — 自训练靠模型生成伪标签, cleanlab 靠模型判断标签质量。当基础模型不够强时, 两者都会失败

### 4.15 Label Propagation (Semi-Supervised Baseline)

**动机**: 作为 kNN 和 MLP 之外的第三种方法对比, 用 sklearn LabelSpreading 在 embedding 空间上做图传播。

**方法**: PCA 降维到 256 维 → sklearn LabelSpreading (kernel='knn', n_neighbors=7, alpha=0.2)

**配置**: 与 Ensemble 实验同时运行, 在 ensemble_proxy.py 中实现

#### Label Propagation 结果

| Train Ratio | LP Acc | LP F1 | LP MAE | MLP Acc | kNN Acc |
|-------------|--------|-------|--------|---------|---------|
| 10% | 0.4078 | 0.2983 | 0.738 | 0.5263 | 0.4576 |
| 20% | 0.4266 | 0.3209 | 0.702 | 0.5436 | 0.4769 |
| 30% | 0.4355 | 0.3219 | 0.684 | 0.5496 | 0.4850 |

#### 关键发现

1. **表现最差**: Accuracy 40-44%, 低于 kNN (46-49%) 和 MLP (53-55%), 三种方法中最弱
2. **受限于同样的 embedding 瓶颈**: LP 通过 embedding 空间传播标签, 与 kNN 依赖相同的信号, 但图传播的 PCA 降维 (4096→256) 进一步损失了信息
3. **半监督的传播噪声**: 未标注样本的初始伪标签质量很低, 在图传播过程中噪声会扩散, 污染原本正确的标签
4. **结论**: 在当前 embedding 质量下, 图方法不是有效的半监督策略

---

## 5. Fusion MLP Train Ratio Scaling (30k 子集)

**最重要发现**: 增加训练数据比增大模型更有效。

### 5.1 Scaling Curve

使用 Fusion MLP v2 (emb+63feat, h=256) 在 30k 子集上:

| Train Ratio | Train | Test | Accuracy | Macro F1 | MAE |
|-------------|-------|------|----------|----------|-----|
| 10% | 3,000 | 27,000 | 0.5339* | 0.3485 | 0.5120 |
| 20% | 6,000 | 24,000 | 0.5404 | 0.3684 | 0.4990 |
| 30% | 9,000 | 21,000 | 0.5442 | 0.3694 | 0.4957 |
| **50%** | **15,000** | **15,000** | **0.5545** | **0.3998** | **0.4826** |
| 70% | 21,000 | 9,000 | 0.5544 | 0.3871 | 0.4809 |
| 90% | 27,000 | 3,000 | 0.5593 | 0.3886 | 0.4763 |

*10% 使用 v1 特征 (35维), 其余使用 v2 特征 (63维)

### 5.2 Per-Class Accuracy 随 Train Ratio 变化

| Class | 10% train | 20% train | 50% train | 90% train |
|-------|-----------|-----------|-----------|-----------|
| 0 | 0.19 | 0.22 | 0.32 | 0.30 |
| 1 | 0.40 | 0.48 | 0.43 | 0.31 |
| 2 | 0.58 | 0.57 | 0.66 | 0.67 |
| 3 | 0.70 | 0.67 | 0.60 | 0.67 |
| 4 | 0.12 | 0.16 | **0.25** | **0.24** |
| 5 | 0.00 | 0.00 | 0.00 | 0.00 |

### 5.3 关键发现

1. **训练数据量是主要瓶颈**: 10%→50% accuracy 提升 +2.1%, macro_f1 提升 +5.1%
2. **少数类显著改善**: class 4 准确率从 0.12 翻倍至 0.25, class 0 从 0.19 升至 0.32
3. **50% 是甜蜜点**: 50%→90% 仅提升 +0.5% accuracy, 收益递减明显
4. **远超 kNN**: 同样 50% train ratio, kNN 仅 0.4726, Fusion MLP 达到 **0.5545** (+8.2%)

### 5.4 Fusion MLP vs kNN Scaling 对比

| Train Ratio | kNN (300k) | Fusion MLP (30k) | 差距 |
|-------------|-----------|-----------------|------|
| 10% | 0.4481 | 0.5339 | +8.6% |
| 50% | 0.4726 | 0.5545 | +8.2% |
| 90% | 0.4826 | 0.5593 | +7.7% |

Fusion MLP 在所有 train ratio 下都大幅优于 kNN, 且优势稳定在 ~8% 左右。

---

## 6. 总排行榜

### 6.1 按 Accuracy 排序 (最佳配置)

| Rank | 方法 | 数据 | Accuracy | Macro F1 | MAE |
|------|------|------|----------|----------|-----|
| 1 | **Skywork Fusion MLP (90% train)** | **30k** | **0.5813** | 0.4280 | **0.4437** |
| 2 | **Skywork Fusion MLP (70% train)** | **30k** | 0.5691 | **0.4452** | 0.4652 |
| 3 | Skywork Fusion MLP (50% train) | 30k | 0.5655 | 0.4414 | 0.4700 |
| 4 | BGE Fusion MLP (90% train, v2) | 30k | 0.5593 | 0.3886 | 0.4763 |
| 5 | BGE Fusion MLP (50% train, v2) | 30k | 0.5545 | 0.3998 | 0.4826 |
| 6 | Skywork Fusion MLP (30% train) | 30k | 0.5527 | 0.4143 | 0.4857 |
| 7 | BGE Fusion MLP (30% train, v2) | 30k | 0.5442 | 0.3694 | 0.4957 |
| 8 | BGE Fusion MLP (10% train, v1) | 30k | 0.5339 | 0.3485 | 0.5120 |
| 9 | Skywork Fusion MLP (10% train) | 30k | 0.5267 | 0.3455 | 0.5232 |
| 10 | Fusion ResNet (10% train, v1) | 30k | 0.5272 | 0.3639 | 0.5261 |
| 11 | Skywork kNN (90% train) | 300k | 0.5144 | 0.4119 | 0.5570 |
| 12 | Text Features Only v1 (MLP) | 30k | 0.5098 | 0.3139 | 0.5504 |
| 13 | GBM fusion (emb+63feat) | 30k | 0.5094 | 0.2880 | 0.5470 |
| 14 | Skywork kNN (50% train) | 300k | 0.5043 | 0.4045 | 0.5711 |
| 15 | ResNet-MLP emb only (h=512, 6L) | 30k | 0.4977 | 0.2872 | 0.5566 |
| 16 | MLP emb only (h=256) | 30k | 0.4943 | 0.2531 | 0.5582 |
| 17 | kNN BGE best (vote, K=100, tau=0.05) | 30k | 0.4484 | 0.3542 | 0.6767 |

*注: Skywork Fusion MLP (90%) 的 test set 较小 (3k), accuracy 参考性略低; 70% 更具代表性。
*注: Skywork Fusion MLP (70%) 同时达到最高 Macro F1 (0.4452), 首次在 accuracy 和 F1 上同时达到新高。

### 6.2 关键 Trade-off

- **Accuracy vs Macro F1**: kNN (0.4484 acc, 0.3542 f1) 的 f1 比很多监督模型都高, 因为它对少数类预测更均匀; 而 MLP 倾向于预测多数类
- **Fusion MLP vs Fusion ResNet**: MLP 准确率更高, ResNet macro_f1 更高, ResNet 在少数类上明显更好
- **更多特征 vs 更多数据**: 增加特征 (35→63) 未带来提升, 但增加训练数据 (3k→15k) 效果显著

---

## 7. 核心结论

1. **Embedding 质量是最大瓶颈, 且已被验证可改善**: bge-large-en-v1.5 是通用语义 embedding, 不捕捉"质量"信号。更换为 Skywork-Reward embedding 后 kNN accuracy 平均提升 +2.98%, MAE 下降 -6.07%, 直接验证了 embedding 质量假设。
2. **Reward Model Embedding 对 kNN 效果显著**: Skywork kNN (50% train) 达到 0.5043 accuracy 和 0.4045 macro_f1, 后者超过所有监督方法, 说明 reward model 的 hidden states 天然包含质量判断信号, 对少数类预测更均匀。
3. **Skywork Fusion MLP 达到全局最优**: Skywork 4096 维 + 63 文本特征, accuracy=0.5813 (90% train), Macro F1=0.4452 (70% train), 首次同时刷新两项指标。但需注意: 低 train ratio (10%) 时 Skywork 略低于 BGE (高维过拟合), 20%+ 后全面超越。
4. **浅层文本特征信号意外地强**: 35 个手工特征 (77K 参数) 比 1024 维 BGE embedding (330K+ 参数) 更有效, 说明该数据集中质量主要由长度、格式、结构等表面因素决定。
5. **Early Fusion 仍是当前最优策略**: embedding + text features 互补, Skywork Fusion MLP 在 50% train 下达到 **56.6%**, 90% train 下达到 **58.1%**。
6. **训练数据量 > Embedding 质量 > 模型容量 > 特征数量**: 增加数据量效果最大, 更换 embedding 其次 (+1~2%), 增大模型无效, 增加特征无效。
7. **类别不平衡是 Macro F1 低的主因 (已验证)**: 均衡 18k 数据集上 Macro F1 从 0.35-0.43 大幅提升至 **0.47-0.57** (+10~14%); class 5 从 0% → 73-81%, class 4 从 12-25% → 35-52%。但 accuracy 略降 1-5%, 说明不平衡时 accuracy 被多数类"虚高"。
8. **树模型不适合此任务**: LightGBM 无法有效利用高维 embedding, 不如 MLP。

---

## 8. 可能的改进方向

| 方向 | 说明 | 预期收益 |
|------|------|----------|
| **在全量 300k 上跑 Fusion MLP** | 当前最佳结果在 30k 子集上; 全量 300k (30k train) 应可进一步提升 | 高 |
| ~~更换 Embedding Model~~ | ~~使用质量感知的 embedding~~ → **已完成**: Skywork-Reward-Llama-3.1-8B embedding, kNN accuracy +2.98%, MAE -6.07% | ✅ 已验证 |
| ~~Skywork Embedding + Fusion MLP~~ | ~~用 Skywork 4096 维替换 BGE 1024 维~~ → **已完成**: 90% train acc=0.5813 (+2.2%), 70% train F1=0.4452 (+5.8%), 新全局最优 | ✅ 已验证 |
| **微调 Embedding** | 在已标注数据上 fine-tune embedding model, 使 embedding 空间按质量聚类 | 中-高 |
| ~~半监督/自训练~~ | ~~用高置信度 proxy label 扩充训练集, 迭代训练~~ → **已完成**: 5 轮自训练, F1 提升 +1.3~2.5% 但 Accuracy 下降 0.3~1.3%, 伪标签准确率仅 ~50-61%, 噪声过大 | ✅ 已验证 (效果有限) |
| ~~均衡数据集实验~~ | ~~验证类别不平衡是否是 Macro F1 低的主因~~ → **已完成**: 均衡 18k 上 F1 提升 +10~14%, class 5 从 0%→81%, 确认不平衡是主因 | ✅ 已验证 |
| ~~Class Weight / Oversample~~ | ~~在不均衡数据上通过 loss 权重或过采样补偿~~ → **已完成**: F1 仅提升 +2~4%, 远不如均衡数据的 +10~14%, 因为不增加信息量 | ✅ 已验证 (效果有限) |
| ~~多标注者标签融合~~ | ~~Majority/Median/Consensus 融合 GPT+Llama+Mistral 标签~~ → **已完成**: 所有融合模式均不如 GPT-only 基线 (Acc -3~8%, F1 -7~19%), 因为训练-评估目标不一致 | ✅ 已验证 (负面结果) |
| ~~集成方法~~ | ~~kNN + 监督分类器 soft voting~~ → **已完成**: Acc 仅提升 +0.1~0.3%, F1 反而下降, best α=0.7~0.8 严重偏向 MLP, kNN 贡献极有限 | ✅ 已验证 (效果有限) |
| ~~标签噪声检测 (Cleanlab)~~ | ~~Confident Learning 检测+清洗噪声标签~~ → **已完成**: ~40% 标签被标为噪声 (过于激进), 清洗后 Acc 下降 0.6~1.2%, 模型准确率太低无法做有效噪声检测 | ✅ 已验证 (负面结果) |
| ~~Label Propagation~~ | ~~图方法半监督标签传播~~ → **已完成**: Acc 仅 40-44%, 远低于 kNN (46-49%) 和 MLP (53-55%), 受限于同样的 embedding 瓶颈 | ✅ 已验证 (负面结果) |

---

## 9. 代码文件索引

| 文件 | 说明 |
|------|------|
| `partial_labeling/proxy_label_generation.py` | kNN proxy label 生成 (支持 vote/regression, softmax/power weighting, prior calibration) |
| `partial_labeling/hyperparam_search.py` | kNN 超参搜索 |
| `partial_labeling/supervised_proxy.py` | 监督分类器 (Linear/MLP/ResNet/Ordinal, Focal Loss, Label Smoothing, Mixup, Feature Fusion) |
| `partial_labeling/feature_extraction.py` | 63 维浅层文本特征提取 (v2, 含可读性/对齐/质量信号) |
| `partial_labeling/gbm_proxy.py` | LightGBM 梯度提升树分类器 |
| `partial_labeling/extract_reward_embeddings.py` | Reward Model embedding 提取 (支持 last_token/mean pooling, 多卡并行分片) |
| `partial_labeling/plot_metrics.py` | 可视化绘图 |
| `run_proxy_knn.sh` | 全量 300k BGE kNN 多 train_ratio 批量实验脚本 |
| `run_proxy_knn_skywork.sh` | 全量 300k Skywork Reward kNN 多 train_ratio 批量实验脚本 |
| `run_skywork_fusion_mlp.sh` | Skywork Fusion MLP 多 train_ratio 批量实验脚本 |
| `run_balanced_skywork_fusion_mlp.sh` | 均衡 18k 数据集 Skywork Fusion MLP 实验脚本 |
| `run_skywork_fusion_mlp_classweight.sh` | Skywork Fusion MLP + class weight 实验脚本 |
| `run_skywork_fusion_mlp_oversample.sh` | Skywork Fusion MLP + 训练集过采样 (无泄露) 实验脚本 |
| `run_skywork_fusion_mlp_label_fusion.sh` | 多标注者标签融合实验 (majority/median/consensus × 6 ratios) |
| `run_skywork_fusion_mlp_selftrain.sh` | 迭代自训练实验 (5 rounds, class-aware thresholds) |
| `run_extract_skywork_embeddings.sh` | Skywork-Reward-Llama-3.1-8B embedding 提取 (8 卡并行) |
| `partial_labeling/ensemble_proxy.py` | kNN + MLP Soft Voting Ensemble + Label Propagation 对比 |
| `partial_labeling/cleanlab_proxy.py` | Cleanlab 标签噪声检测 + 清洗 (remove/relabel) |
| `run_skywork_ensemble.sh` | Ensemble 实验脚本 (3 train ratios, alpha sweep) |
| `run_skywork_cleanlab.sh` | Cleanlab 实验脚本 (3 train ratios × 2 clean methods) |
